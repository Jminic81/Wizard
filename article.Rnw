\documentclass{article}
\usepackage{natbib}

<<echo=FALSE>>=
packages<-c('dplyr','gutenbergr','stringr','tidytext','tm','wordcloud')
knitr::write_bib(packages,file='article.bib')
@


\begin{document}



\title{Using R to create a wordcloud from text in an ebook}
\author{Judy Minichelli}
\maketitle

\begin{abstract}
The article gives instructions on how to download text from an ebook and create a 
wordcloud in R.  A wordclouds is a data visualization that shows the most commonly used words in a large text dataset where size is proportional to frequency; words with the highest count appear larger and in bold.  The ebook used in this example
is "The Wonderful Wizard of Oz"

\end{abstract}

\textit{The Wonderful Wizard of Oz} was written by Frank Baum and published in 1900. It was the basis for the 1902 Broadway musical and the classic 1939 movie starring Judy Garland. 

\section{R Packages}

The following packages were installed and brought in with library: dplyr, gutenbergr, stringr, tidytext, tm, wordcloud.

    

The function below stores the result of the book text download in the dataframe "wizard". 

<<message=FALSE,warning=FALSE>>=
library(gutenbergr)
wizard<-gutenberg_download(55)
@

This dataframe has two columns, one for each line in the book.

\noindent For this exercise, it is not necessary to exclude chapter headings and the first few pages of text; however, the procedures below will accomplish the task.  

\section{How to Clean Data}

<<>>=
library(stringr)
library(dplyr)
wizard<-wizard%>%
  filter(!str_detect(wizard$text,'^CHAPTER'))
@

The actual text begins on line 10 and ends on 4721 so the wizard data frame can be redefined to exclude the first 9 lines. 

<<message=FALSE,warning=FALSE>>=
wizard<-wizard[10:4721,]
@

\section{The Wordcloud}
To make the wordcloud, break the text lines into words.

<<message=FALSE,warning=FALSE>>=
library(tidytext)
words_df<-wizard%>%
  unnest_tokens(word,text)

words_df
@

Remove commonly used "generic" words from the data frame, for example articles, prepositions, and pronouns like "the", "after", and "you" from the data frame using the stop\_words command.

<<>>=
words_df<-words_df%>%
  filter(!(word %in% stop_words$word))

words_df
@

Calculate the frequencies of the remaining unique words.  

<<message=FALSE,warning=FALSE>>=
word_freq<-words_df%>%
  group_by(word)%>%
  summarize(count=n())

word_freq
@

Generate the wordcloud. If there are too many or too few words, adjust "n" in "min.freq=n" to change the minimum number of occurances required for the word to appear in the wordcloud.  The number of colors used in the graphic can be changed by adjusting "n" in "colors=brewer.pal(n,'Dark2').  This helps further differentiate  the words used with higher frequency.  

<<message=FALSE,warning=FALSE>>=
library(wordcloud)
library(tm)
wordcloud(word_freq$word,word_freq$count,min.freq=20,colors=brewer.pal(4,'Dark2'))
@

\bibliographystyle{apa}
\bibliography{article,wiz}
\nocite{*}

\end{document}